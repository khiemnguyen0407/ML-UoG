{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import torch as pt\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# %load_ext autoreload\n",
    "# %autoreload 2\n",
    "\n",
    "pt.set_printoptions(linewidth=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = pt.device(\"cuda:0\" if pt.cuda.is_available() else \"cpu\")\n",
    "hidden_size = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "class DinosDataset(Dataset):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        with open('dinos.txt') as f:\n",
    "            content = f.read().lower()\n",
    "            self.vocab = sorted(set(content))\n",
    "            self.vocab_size = len(self.vocab)\n",
    "            self.lines = content.splitlines()\n",
    "        self.ch_to_idx = {c:i for i, c in enumerate(self.vocab)}\n",
    "        self.idx_to_ch = {i:c for i, c in enumerate(self.vocab)}\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        line = self.lines[index]\n",
    "        x_str = ' ' + line #add a space at the beginning, which indicates a vector of zeros.\n",
    "        y_str = line + '\\n'\n",
    "        x = pt.zeros([len(x_str), self.vocab_size], dtype=pt.float)\n",
    "        y = pt.empty(len(x_str), dtype=pt.long)\n",
    "        \n",
    "        y[0] = self.ch_to_idx[y_str[0]]\n",
    "        #we start from the second character because the first character of x was nothing(vector of zeros).\n",
    "        for i, (x_ch, y_ch) in enumerate(zip(x_str[1:], y_str[1:]), 1):\n",
    "            x[i][self.ch_to_idx[x_ch]] = 1\n",
    "            y[i] = self.ch_to_idx[y_ch]\n",
    "        \n",
    "        return x, y\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_ds = DinosDataset()\n",
    "trn_dl = DataLoader(trn_ds, batch_size=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(LSTM, self).__init__()\n",
    "        self.linear_f = nn.Linear(input_size + hidden_size, hidden_size)\n",
    "        self.linear_u = nn.Linear(input_size + hidden_size, hidden_size)\n",
    "        self.linear_c = nn.Linear(input_size + hidden_size, hidden_size)\n",
    "        self.linear_o = nn.Linear(input_size + hidden_size, hidden_size)\n",
    "        \n",
    "        self.i2o = nn.Linear(hidden_size, output_size)\n",
    "        \n",
    "    def forward(self, c_prev, h_prev, x):\n",
    "        combined = pt.cat([x, h_prev], 1)\n",
    "        f = pt.sigmoid(self.linear_f(combined))\n",
    "        u = pt.sigmoid(self.linear_u(combined))\n",
    "        c_tilde = pt.tanh(self.linear_c(combined))\n",
    "        c = f*c_prev + u*c_tilde\n",
    "        o = pt.sigmoid(self.linear_o(combined))\n",
    "        h = o*pt.tanh(c)\n",
    "        y = self.i2o(h)\n",
    "        \n",
    "        return c, h, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LSTM(trn_ds.vocab_size, hidden_size, trn_ds.vocab_size).to(device)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def print_sample(sample_idxs):\n",
    "    print(trn_ds.idx_to_ch[sample_idxs[0]].upper(), end='')\n",
    "    [print(trn_ds.idx_to_ch[x], end='') for x in sample_idxs[1:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def sample(model):\n",
    "    model.eval()\n",
    "    c_prev = pt.zeros([1, hidden_size], dtype=pt.float, device=device)\n",
    "    h_prev = pt.zeros_like(c_prev)\n",
    "    x = c_prev.new_zeros([1, trn_ds.vocab_size])\n",
    "    sampled_indexes = []\n",
    "    idx = -1\n",
    "    n_chars = 1\n",
    "    newline_char_idx = trn_ds.ch_to_idx['\\n']\n",
    "    with pt.no_grad():\n",
    "        while n_chars != 50 and idx != newline_char_idx:\n",
    "            c_prev, h_prev, y_pred = model(c_prev, h_prev, x)\n",
    "            softmax_scores = pt.softmax(y_pred, 1).cpu().numpy().ravel()\n",
    "            np.random.seed(np.random.randint(1, 5000))\n",
    "            idx = np.random.choice(np.arange(trn_ds.vocab_size), p=softmax_scores)\n",
    "            sampled_indexes.append(idx)\n",
    "            \n",
    "            x = (y_pred == y_pred.max(1)[0]).float()\n",
    "            \n",
    "            n_chars += 1\n",
    "            \n",
    "            if n_chars == 50:\n",
    "                sampled_indexes.append(newline_char_idx)\n",
    "                \n",
    "    model.train()\n",
    "    return sampled_indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def train_one_epoch(model, loss_fn, optimizer):\n",
    "    model.train()\n",
    "    for line_num, (x, y) in enumerate(trn_dl):\n",
    "        loss = 0\n",
    "        optimizer.zero_grad()\n",
    "        c_prev = pt.zeros([1, hidden_size], dtype=pt.float, device=device)\n",
    "        h_prev = pt.zeros_like(c_prev)\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        for i in range(x.shape[1]):\n",
    "            c_prev, h_prev, y_pred = model(c_prev, h_prev, x[:, i])\n",
    "            loss += loss_fn(y_pred, y[:, i])\n",
    "            \n",
    "        if (line_num+1) % 100 == 0:\n",
    "            print_sample(sample(model))\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def train(model, loss_fn, optimizer, dataset='dinos', epochs=1):\n",
    "    for e in range(1, epochs+1):\n",
    "        print(f'{\"-\"*20} Epoch {e} {\"-\"*20}')\n",
    "        train_one_epoch(model, loss_fn, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- Epoch 1 --------------------\n",
      "Svagrus\n",
      "Atataaksgrrus\n",
      "Rjconyrroaurus\n",
      "Iraorisaurus\n",
      "Hciocaurus\n",
      "Iggutaurus\n",
      "Tmgasaisaurus\n",
      "Mkornysaurur\n",
      "Lcgucaurus\n",
      "Magesgicaurus\n",
      "Bstsoaurus\n",
      "Mpurapaurus\n",
      "Gtaarn\n",
      "Lisiraurus\n",
      "Vgstiurus\n",
      "-------------------- Epoch 2 --------------------\n",
      "Zrnortaisaurus\n",
      "Tccpraurus\n",
      "Atahusturus\n",
      "Ersivtmsaurus\n",
      "Fsbunturus\n",
      "Litenasdaurus\n",
      "Trnasoitaurus\n",
      "Kicdscsaurus\n",
      "Ailsraurus\n",
      "Psgtspurus\n",
      "Yslscurus\n",
      "Escrntanaurus\n",
      "Gidraskrudossurus\n",
      "Zshost\n",
      "Inaesasaurus\n",
      "-------------------- Epoch 3 --------------------\n",
      "Amdtnaurus\n",
      "Ntctsaurus\n",
      "Ytnospurus\n",
      "Saogtagaurus\n",
      "Hmaucitaurus\n",
      "Leurovhurus\n",
      "Inais\n",
      "Sltagssaurus\n",
      "Ataotaurus\n",
      "Lcurovcurus\n",
      "Hidrtcois\n",
      "Ctreompuras\n",
      "Kurtissaurus\n",
      "Ysgosaurus\n",
      "Scohtlrus\n",
      "-------------------- Epoch 4 --------------------\n",
      "Larehcsaurus\n",
      "Stsonaurus\n",
      "Prsahocaurus\n",
      "Agonasaurus\n",
      "Aiurudlus\n",
      "Dslewtsaurus\n",
      "Alraoiaurus\n",
      "Lanomaurus\n",
      "Tdpionnsaurus\n",
      "Suahaaisaurus\n",
      "Siangsaurus\n",
      "Wourus\n",
      "Mlsonysaurus\n",
      "Laancsng\n",
      "Ctmaraurus\n",
      "-------------------- Epoch 5 --------------------\n",
      "Ahurodaurus\n",
      "Siuorauros\n",
      "Ahngsaurus\n",
      "Ailromes\n",
      "Iuincsaurus\n",
      "Kvomospurus\n",
      "Scoesaauras\n",
      "Slearasaurus\n",
      "Sndrplwaurus\n",
      "Kiamsaurus\n",
      "Siaodaurus\n",
      "Jvlucsaurus\n",
      "Kwsksosbaurus\n",
      "Slsaarocaurus\n",
      "Scdritosaurus\n",
      "-------------------- Epoch 6 --------------------\n",
      "Jwphirsaurus\n",
      "Ardtarrur\n",
      "Cschasahuosashus\n",
      "Stlusaurus\n",
      "Kbgrcoht\n",
      "Briandsaurus\n",
      "Xisgshurus\n",
      "Juraposaphalu\n",
      "Sltaeosaurus\n",
      "Atbhunomnpthomimus\n"
     ]
    }
   ],
   "source": [
    "train(model, loss_fn, optimizer, epochs=2000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
